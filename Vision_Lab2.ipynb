{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vision Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Merna177/InceptionV2/blob/master/Vision_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YR6raxFxhOs",
        "colab_type": "text"
      },
      "source": [
        "# Keras Reading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri6QPX6-xwnK",
        "colab_type": "text"
      },
      "source": [
        "**Labels**:\n",
        "0: airplane\n",
        "1: automobile\n",
        "2: bird\n",
        "3: cat\n",
        "4: deer\n",
        "5: dog\n",
        "6: frog\n",
        "7: horse\n",
        "8: ship\n",
        "9: truck\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSqBznok1RnK",
        "colab_type": "text"
      },
      "source": [
        "50000 example  for training and 10000 for testing \n",
        "\n",
        "Using one hot coding for the labels to be used in keras model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKaCPZRK-AcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "import keras\n",
        "def load_data():\n",
        " # load dataset\n",
        " (xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n",
        " ytrain = keras.utils.to_categorical(ytrain,10)\n",
        " ytest = keras.utils.to_categorical(ytest,10)\n",
        " return xtrain,ytrain,xtest,ytest\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wheEvw9B39YA",
        "colab_type": "text"
      },
      "source": [
        "Normalize the data by dividing each pixel by the max value(255)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MduwLCJs393w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeData(xtrain,xtest):\n",
        "  xtrain = xtrain.astype('float32')\n",
        "  xtest = xtest.astype('float32')\n",
        "  # normalize to range (0,1)\n",
        "  xtrain = xtrain / 255.0\n",
        "  xtest = xtest / 255.0\n",
        "  return xtrain,xtest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPJ-pyZs8Swe",
        "colab_type": "text"
      },
      "source": [
        "show some images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRQug4s38UVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_images(xtrain):\n",
        "  k = 0\n",
        "  for i in range(0,4):\n",
        "    for j in range(0,4):\n",
        "      pyplot.subplot2grid((4,4),(i,j))\n",
        "      pyplot.imshow((xtrain[k]))\n",
        "      k = k+1\n",
        "  pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFO3mHaW2eNE",
        "colab_type": "code",
        "outputId": "9f5a99cd-de9b-4d8a-b760-3c6915ebdded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "xtrain,ytrain,xtest,ytest = load_data()\n",
        "show_images(xtrain[:16])\n",
        "xtrain,xtest = normalizeData(xtrain,xtest)\n",
        "print(\"xtrain shape\",xtrain.shape)\n",
        "print(\"xtest shape\",xtest.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6bbc71d9bf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xtrain shape\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xtest shape\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'show_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvLqLhAm8CCy",
        "colab_type": "text"
      },
      "source": [
        "Implementing model's architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv-O340O8GAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, Dropout,MaxPooling2D\n",
        "def create_model():\n",
        " model = Sequential()\n",
        " model.add(Conv2D(filters=32, kernel_size=3, input_shape=(32,32,3)))\n",
        " model.add(Conv2D(filters=32, kernel_size=3))\n",
        " model.add(MaxPooling2D(pool_size=2 ))\n",
        " model.add(Dropout(0.2))\n",
        " model.add(Conv2D(filters=64, kernel_size=3))\n",
        " model.add(Conv2D(filters=64, kernel_size=3))\n",
        " model.add(MaxPooling2D(pool_size=2 ))\n",
        " model.add(Dropout(0.2))\n",
        " model.add(Flatten())\n",
        " model.add(Dense(256, activation='relu'))\n",
        " model.add(Dense(10, activation='softmax'))\n",
        " return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG-Zex-wCygb",
        "colab_type": "code",
        "outputId": "7497eafb-a702-44f2-9785-39125998f120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(xtrain[0].shape)\n",
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSUX3MycDZOq",
        "colab_type": "text"
      },
      "source": [
        "fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBTGnw4TDaMt",
        "colab_type": "code",
        "outputId": "d373a016-fa28-421e-e7bf-844cf830f58a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "from keras.optimizers import adam\n",
        "op = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=op, metrics=['accuracy'])\n",
        "history = model.fit(xtrain, ytrain, epochs=60, batch_size=50, verbose =2,validation_split=0.1, callbacks =[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/60\n",
            " - 25s - loss: 1.4047 - acc: 0.5017 - val_loss: 1.0684 - val_acc: 0.6248\n",
            "Epoch 2/60\n",
            " - 17s - loss: 1.0199 - acc: 0.6456 - val_loss: 0.9407 - val_acc: 0.6740\n",
            "Epoch 3/60\n",
            " - 17s - loss: 0.8804 - acc: 0.6960 - val_loss: 0.8772 - val_acc: 0.7026\n",
            "Epoch 4/60\n",
            " - 17s - loss: 0.7850 - acc: 0.7293 - val_loss: 0.8962 - val_acc: 0.7000\n",
            "Epoch 5/60\n",
            " - 17s - loss: 0.7031 - acc: 0.7546 - val_loss: 0.8798 - val_acc: 0.6976\n",
            "Epoch 6/60\n",
            " - 17s - loss: 0.6384 - acc: 0.7771 - val_loss: 0.8564 - val_acc: 0.7232\n",
            "Epoch 7/60\n",
            " - 17s - loss: 0.5756 - acc: 0.7989 - val_loss: 0.9673 - val_acc: 0.7114\n",
            "Epoch 8/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-4d9b5a802fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3fKzSyHDhbW",
        "colab_type": "text"
      },
      "source": [
        "predict test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhI3f6XQDo_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predTest = model.predict_classes(xtest,batch_size = 10)\n",
        "score = model.evaluate(xtest, ytest, verbose=0, batch_size=10)\n",
        "print('loss','accuracy:')\n",
        "print(score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q64NROYeEwZz",
        "colab_type": "text"
      },
      "source": [
        "plotting accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os1c2PC-EyPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1AhgA4qE77f",
        "colab_type": "code",
        "outputId": "8a1b875a-a4c7-49da-bc51-422e4e152445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "summarize(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noBtjTJqwQDfGmDTx/wGZ450KbUyU4gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdOAG0Sq_FHc",
        "colab_type": "text"
      },
      "source": [
        "# Inception Model V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRbsiBCyIWyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from  math import ceil\n",
        "n = len(xtrain)\n",
        "xrtrain = xtrain[ceil(n*0.1):]\n",
        "yrtrain = ytrain[ceil(n*0.1):]\n",
        "xvalidation = xtrain[0:math.ceil(n * 0.1)]\n",
        "yvalidation = ytrain[0:math.ceil(n * 0.1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd2lcrSAFx-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam,SGD\n",
        "from keras.layers import Input,Dense, Activation, Flatten, Conv2D, Dropout,MaxPooling2D,concatenate,AveragePooling2D\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "kernel_init = keras.initializers.glorot_uniform()\n",
        "bias_init = keras.initializers.Constant(value=0.2)\n",
        "def inception_module_first(inputLayer):\n",
        "  layer1 =  Conv2D(128,(1,1),strides=2,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "\n",
        "  layer2 = AveragePooling2D((1,1),padding='same')(inputLayer)\n",
        "  layer2 =  Conv2D(128,(1,1),strides=2,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer2)\n",
        "    \n",
        "  layer3 =  Conv2D(128,(1,1),strides=2,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "  layer3 = Conv2D(256,(3,3),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer3)\n",
        "\n",
        "  layer4 = Conv2D(128,(1,1),strides=2,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "  layer4 =  Conv2D(128,(3,3),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "  layer4 = Conv2D(256,(3,3),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "\n",
        "  output = concatenate([layer1,layer2,layer3,layer4],axis=3)\n",
        "  print(\"output\",output);\n",
        "  return output\n",
        "def inception_module_second(inputLayer):\n",
        "    layer1= Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "\n",
        "    layer2 = MaxPooling2D((1,1),padding='same')(inputLayer)\n",
        "    layer2 =  Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer2)\n",
        "\n",
        "    layer3 = Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "    layer3 = Conv2D(64,(1,5),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer3)\n",
        "    layer3 = Conv2D(64,(5,1),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer3)\n",
        "\n",
        "    layer4 = Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "    layer4 = Conv2D(64,(1,5),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "    layer4 = Conv2D(64,(5,1),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "    layer4 = Conv2D(64,(1,5),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "    layer4 = Conv2D(64,(5,1),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "\n",
        "    output = concatenate([layer1,layer2,layer3,layer4],axis=3)\n",
        "    print(\"outpput figure 6\",output)\n",
        "    return output\n",
        "\n",
        "def inception_module_third(inputLayer):\n",
        "  layer1= Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "\n",
        "  layer2 = AveragePooling2D((1,1),padding='same')(inputLayer)\n",
        "  layer2 =  Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer2)\n",
        "\n",
        "  layer3 = Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "  layer3p1 = Conv2D(64,(1,3),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer3)\n",
        "  layer3p2 = Conv2D(64,(3,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer3)\n",
        "  \n",
        "  layer4 =  Conv2D(64,(1,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(inputLayer)\n",
        "  layer4 = Conv2D(64,(3,3),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "  layer4p1 = Conv2D(64,(1,3),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "  layer4p2 = Conv2D(64,(3,1),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer4)\n",
        "  \n",
        "  output = concatenate([layer1,layer2,layer3p1,layer3p2,layer4p1,layer4p2],axis=3)\n",
        "  print(\"output figure 7\",output)\n",
        "  return output\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFE3FYWJ_HWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def InceptionV2(input_image):\n",
        "  layer1= Conv2D(32,(3,3),strides=2,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(input_image)\n",
        "  print(\"layer1\",layer1)\n",
        "\n",
        "  layer1= Conv2D(32,(3,3),strides=1,padding='valid',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer1)\n",
        "  print(\"layer2\",layer1)\n",
        "\n",
        "  layer1=Conv2D(64,(3,3),strides=1,padding='same',activation = 'relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer1)\n",
        "  print(\"layer3\",layer1)\n",
        "\n",
        "  layer1 = MaxPooling2D((3,3),strides=2,padding='same')(layer1)\n",
        "  print(\"layer4\",layer1)\n",
        "  x1 =  Flatten()(layer1)\n",
        "  x1 = Dense(1024, activation='relu')(x1)\n",
        "  x1 = Dropout(0.2)(x1)\n",
        "  x1 = Dense(10, activation='softmax', name='auxilliary_output_1')(x1)\n",
        "  layer1 = Conv2D(80,(3,3),strides=1,padding='valid',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer1)\n",
        "  print(\"layer5\",layer1)\n",
        "\n",
        "  layer1= Conv2D(192,(3,3),strides=2,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer1)\n",
        "  print(\"layer6\",layer1)\n",
        "\n",
        "  layer1 = Conv2D(288,(3,3),strides=1,padding='same',activation='relu',kernel_initializer=kernel_init, bias_initializer=bias_init)(layer1)\n",
        "  print(\"layer7\",layer1)\n",
        "  x2 =  Flatten()(layer1)\n",
        "  x2 = Dense(1024, activation='relu')(x2)\n",
        "  x2 = Dropout(0.7)(x2)\n",
        "  x2 = Dense(10, activation='softmax',name='auxilliary_output_2')(x2)\n",
        "  layer1 = inception_module_first(layer1)\n",
        "  layer1 = inception_module_first(layer1)\n",
        "  layer1 = inception_module_first(layer1)\n",
        "\n",
        "  layer1 = inception_module_second(layer1)\n",
        "  layer1 = inception_module_second(layer1)\n",
        "  layer1 = inception_module_second(layer1)\n",
        "  layer1 = inception_module_second(layer1)\n",
        "  layer1 = inception_module_second(layer1)\n",
        "  layer1 = inception_module_third(layer1)\n",
        "  layer1 = inception_module_third(layer1)\n",
        "\n",
        "  layer1 = AveragePooling2D((2,2),strides=2,padding='same')(layer1)\n",
        "  layer1 = Flatten()(layer1)\n",
        "\n",
        "  predictions = Dense(10, activation='softmax',name='final_prediction')(layer1)\n",
        "  return x1,x2,predictions \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAVsqwzsEydb",
        "colab_type": "code",
        "outputId": "020cb89d-2efa-4728-9f90-f5958c5ce49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "import numpy as np\n",
        "#xtrain = np.resize(xtrain,(50000,100,100,3))\n",
        "print(xtrain.shape)\n",
        "#xtest = np.resize(xtest,(10000,100,100,3))\n",
        "input_image = Input(shape=(32,32,3))\n",
        "output_inception_v2,x1,x2 = InceptionV2(input_image)\n",
        "print(output_inception_v2,x1,x2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "layer1 Tensor(\"conv2d_685/Relu:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
            "layer2 Tensor(\"conv2d_686/Relu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
            "layer3 Tensor(\"conv2d_687/Relu:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
            "layer4 Tensor(\"max_pooling2d_74/MaxPool:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
            "layer5 Tensor(\"conv2d_688/Relu:0\", shape=(?, 5, 5, 80), dtype=float32)\n",
            "layer6 Tensor(\"conv2d_689/Relu:0\", shape=(?, 3, 3, 192), dtype=float32)\n",
            "layer7 Tensor(\"conv2d_690/Relu:0\", shape=(?, 3, 3, 288), dtype=float32)\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "output Tensor(\"concatenate_71/concat:0\", shape=(?, 2, 2, 768), dtype=float32)\n",
            "output Tensor(\"concatenate_72/concat:0\", shape=(?, 1, 1, 768), dtype=float32)\n",
            "output Tensor(\"concatenate_73/concat:0\", shape=(?, 1, 1, 768), dtype=float32)\n",
            "outpput figure 6 Tensor(\"concatenate_74/concat:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
            "outpput figure 6 Tensor(\"concatenate_75/concat:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
            "outpput figure 6 Tensor(\"concatenate_76/concat:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
            "outpput figure 6 Tensor(\"concatenate_77/concat:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
            "outpput figure 6 Tensor(\"concatenate_78/concat:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
            "output figure 7 Tensor(\"concatenate_79/concat:0\", shape=(?, 1, 1, 384), dtype=float32)\n",
            "output figure 7 Tensor(\"concatenate_80/concat:0\", shape=(?, 1, 1, 384), dtype=float32)\n",
            "Tensor(\"auxilliary_output_1_1/Softmax:0\", shape=(?, 10), dtype=float32) Tensor(\"auxilliary_output_2_6/Softmax:0\", shape=(?, 10), dtype=float32) Tensor(\"final_prediction_1/Softmax:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2jfNKwkVkCN",
        "colab_type": "code",
        "outputId": "28ba5a34-4569-4fd4-d72d-0e5b0a281fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "inceptionV2Model= Model(inputs=input_image,outputs =[output_inception_v2 ,x1,x2])\n",
        "print(inceptionV2Model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_685 (Conv2D)             (None, 16, 16, 32)   896         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_686 (Conv2D)             (None, 14, 14, 32)   9248        conv2d_685[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_687 (Conv2D)             (None, 14, 14, 64)   18496       conv2d_686[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_74 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_687[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_688 (Conv2D)             (None, 5, 5, 80)     46160       max_pooling2d_74[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_689 (Conv2D)             (None, 3, 3, 192)    138432      conv2d_688[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_690 (Conv2D)             (None, 3, 3, 288)    497952      conv2d_689[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_695 (Conv2D)             (None, 2, 2, 128)    36992       conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 3, 3, 288)    0           conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_693 (Conv2D)             (None, 2, 2, 128)    36992       conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_696 (Conv2D)             (None, 2, 2, 128)    147584      conv2d_695[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_691 (Conv2D)             (None, 2, 2, 128)    36992       conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_692 (Conv2D)             (None, 2, 2, 128)    36992       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_694 (Conv2D)             (None, 2, 2, 256)    295168      conv2d_693[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_697 (Conv2D)             (None, 2, 2, 256)    295168      conv2d_696[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 2, 2, 768)    0           conv2d_691[0][0]                 \n",
            "                                                                 conv2d_692[0][0]                 \n",
            "                                                                 conv2d_694[0][0]                 \n",
            "                                                                 conv2d_697[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_702 (Conv2D)             (None, 1, 1, 128)    98432       concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 2, 2, 768)    0           concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_700 (Conv2D)             (None, 1, 1, 128)    98432       concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_703 (Conv2D)             (None, 1, 1, 128)    147584      conv2d_702[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_698 (Conv2D)             (None, 1, 1, 128)    98432       concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_699 (Conv2D)             (None, 1, 1, 128)    98432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_701 (Conv2D)             (None, 1, 1, 256)    295168      conv2d_700[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_704 (Conv2D)             (None, 1, 1, 256)    295168      conv2d_703[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 1, 1, 768)    0           conv2d_698[0][0]                 \n",
            "                                                                 conv2d_699[0][0]                 \n",
            "                                                                 conv2d_701[0][0]                 \n",
            "                                                                 conv2d_704[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_709 (Conv2D)             (None, 1, 1, 128)    98432       concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 1, 1, 768)    0           concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_707 (Conv2D)             (None, 1, 1, 128)    98432       concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_710 (Conv2D)             (None, 1, 1, 128)    147584      conv2d_709[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_705 (Conv2D)             (None, 1, 1, 128)    98432       concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_706 (Conv2D)             (None, 1, 1, 128)    98432       average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_708 (Conv2D)             (None, 1, 1, 256)    295168      conv2d_707[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_711 (Conv2D)             (None, 1, 1, 256)    295168      conv2d_710[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 1, 1, 768)    0           conv2d_705[0][0]                 \n",
            "                                                                 conv2d_706[0][0]                 \n",
            "                                                                 conv2d_708[0][0]                 \n",
            "                                                                 conv2d_711[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_717 (Conv2D)             (None, 1, 1, 64)     49216       concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_718 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_717[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_714 (Conv2D)             (None, 1, 1, 64)     49216       concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_719 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_718[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_75 (MaxPooling2D) (None, 1, 1, 768)    0           concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_715 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_714[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_720 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_719[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_712 (Conv2D)             (None, 1, 1, 64)     49216       concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_713 (Conv2D)             (None, 1, 1, 64)     49216       max_pooling2d_75[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_716 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_715[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_721 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_720[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 1, 1, 256)    0           conv2d_712[0][0]                 \n",
            "                                                                 conv2d_713[0][0]                 \n",
            "                                                                 conv2d_716[0][0]                 \n",
            "                                                                 conv2d_721[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_727 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_728 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_727[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_724 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_729 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_728[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_76 (MaxPooling2D) (None, 1, 1, 256)    0           concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_725 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_724[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_730 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_729[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_722 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_723 (Conv2D)             (None, 1, 1, 64)     16448       max_pooling2d_76[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_726 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_725[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_731 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_730[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 1, 1, 256)    0           conv2d_722[0][0]                 \n",
            "                                                                 conv2d_723[0][0]                 \n",
            "                                                                 conv2d_726[0][0]                 \n",
            "                                                                 conv2d_731[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_737 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_738 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_737[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_734 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_739 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_738[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_77 (MaxPooling2D) (None, 1, 1, 256)    0           concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_735 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_734[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_740 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_739[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_732 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_733 (Conv2D)             (None, 1, 1, 64)     16448       max_pooling2d_77[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_736 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_735[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_741 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_740[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 1, 1, 256)    0           conv2d_732[0][0]                 \n",
            "                                                                 conv2d_733[0][0]                 \n",
            "                                                                 conv2d_736[0][0]                 \n",
            "                                                                 conv2d_741[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_747 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_748 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_747[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_744 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_749 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_748[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_78 (MaxPooling2D) (None, 1, 1, 256)    0           concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_745 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_744[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_750 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_749[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_742 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_743 (Conv2D)             (None, 1, 1, 64)     16448       max_pooling2d_78[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_746 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_745[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_751 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_750[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 1, 1, 256)    0           conv2d_742[0][0]                 \n",
            "                                                                 conv2d_743[0][0]                 \n",
            "                                                                 conv2d_746[0][0]                 \n",
            "                                                                 conv2d_751[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_757 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_758 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_757[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_754 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_759 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_758[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_79 (MaxPooling2D) (None, 1, 1, 256)    0           concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_755 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_754[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_760 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_759[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_752 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_753 (Conv2D)             (None, 1, 1, 64)     16448       max_pooling2d_79[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_756 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_755[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_761 (Conv2D)             (None, 1, 1, 64)     20544       conv2d_760[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 1, 1, 256)    0           conv2d_752[0][0]                 \n",
            "                                                                 conv2d_753[0][0]                 \n",
            "                                                                 conv2d_756[0][0]                 \n",
            "                                                                 conv2d_761[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_767 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 1, 1, 256)    0           concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_764 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_768 (Conv2D)             (None, 1, 1, 64)     36928       conv2d_767[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_762 (Conv2D)             (None, 1, 1, 64)     16448       concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_763 (Conv2D)             (None, 1, 1, 64)     16448       average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_765 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_764[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_766 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_764[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_769 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_768[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_770 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_768[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 1, 1, 384)    0           conv2d_762[0][0]                 \n",
            "                                                                 conv2d_763[0][0]                 \n",
            "                                                                 conv2d_765[0][0]                 \n",
            "                                                                 conv2d_766[0][0]                 \n",
            "                                                                 conv2d_769[0][0]                 \n",
            "                                                                 conv2d_770[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_776 (Conv2D)             (None, 1, 1, 64)     24640       concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 1, 1, 384)    0           concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_773 (Conv2D)             (None, 1, 1, 64)     24640       concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_777 (Conv2D)             (None, 1, 1, 64)     36928       conv2d_776[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_771 (Conv2D)             (None, 1, 1, 64)     24640       concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_772 (Conv2D)             (None, 1, 1, 64)     24640       average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_774 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_773[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_775 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_773[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_778 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_777[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_779 (Conv2D)             (None, 1, 1, 64)     12352       conv2d_777[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_19 (Flatten)            (None, 3136)         0           max_pooling2d_74[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_20 (Flatten)            (None, 2592)         0           conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 1, 1, 384)    0           conv2d_771[0][0]                 \n",
            "                                                                 conv2d_772[0][0]                 \n",
            "                                                                 conv2d_774[0][0]                 \n",
            "                                                                 conv2d_775[0][0]                 \n",
            "                                                                 conv2d_778[0][0]                 \n",
            "                                                                 conv2d_779[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 1024)         3212288     flatten_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 1024)         2655232     flatten_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 1, 1, 384)    0           concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 1024)         0           dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 1024)         0           dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 384)          0           average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "auxilliary_output_1 (Dense)     (None, 10)           10250       dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "auxilliary_output_2 (Dense)     (None, 10)           10250       dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "final_prediction (Dense)        (None, 10)           3850        flatten_21[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 11,165,614\n",
            "Trainable params: 11,165,614\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbYlCwuxcCsd",
        "colab_type": "code",
        "outputId": "6ecf2675-7a86-4a14-bc7d-1537844c7c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "initial_lrate = 0.01\n",
        "import math\n",
        "import timeit\n",
        "\n",
        "def decay(epoch, steps=100):\n",
        "    initial_lrate = 0.01\n",
        "    drop = 0.96\n",
        "    epochs_drop = 8\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "sgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n",
        "\n",
        "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
        "\n",
        "inceptionV2Model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "start = timeit.default_timer()\n",
        "history = inceptionV2Model.fit(xtrain, [ytrain,ytrain,ytrain], epochs=50, batch_size=256, verbose =2,validation_data=(xvalidation, [yvalidation, yvalidation, yvalidation]), callbacks =[lr_sc])\n",
        "stop = timeit.default_timer()\n",
        "print('Time taken to train the model:' ,stop - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 5000 samples\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
            " - 48s - loss: 6.1732 - auxilliary_output_1_loss: 1.8898 - auxilliary_output_2_loss: 2.0663 - final_prediction_loss: 2.2171 - auxilliary_output_1_acc: 0.3127 - auxilliary_output_2_acc: 0.2287 - final_prediction_acc: 0.1391 - val_loss: 5.2945 - val_auxilliary_output_1_loss: 1.5529 - val_auxilliary_output_2_loss: 1.7464 - val_final_prediction_loss: 1.9952 - val_auxilliary_output_1_acc: 0.4544 - val_auxilliary_output_2_acc: 0.3644 - val_final_prediction_acc: 0.1972\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.01.\n",
            " - 26s - loss: 4.8253 - auxilliary_output_1_loss: 1.4036 - auxilliary_output_2_loss: 1.5912 - final_prediction_loss: 1.8306 - auxilliary_output_1_acc: 0.4958 - auxilliary_output_2_acc: 0.4137 - final_prediction_acc: 0.2818 - val_loss: 4.1265 - val_auxilliary_output_1_loss: 1.2101 - val_auxilliary_output_2_loss: 1.3603 - val_final_prediction_loss: 1.5562 - val_auxilliary_output_1_acc: 0.5802 - val_auxilliary_output_2_acc: 0.5178 - val_final_prediction_acc: 0.4152\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.01.\n",
            " - 26s - loss: 4.1220 - auxilliary_output_1_loss: 1.2060 - auxilliary_output_2_loss: 1.3859 - final_prediction_loss: 1.5302 - auxilliary_output_1_acc: 0.5733 - auxilliary_output_2_acc: 0.4948 - final_prediction_acc: 0.4246 - val_loss: 3.6647 - val_auxilliary_output_1_loss: 1.0410 - val_auxilliary_output_2_loss: 1.1963 - val_final_prediction_loss: 1.4273 - val_auxilliary_output_1_acc: 0.6342 - val_auxilliary_output_2_acc: 0.5664 - val_final_prediction_acc: 0.4688\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.01.\n",
            " - 26s - loss: 3.6616 - auxilliary_output_1_loss: 1.0638 - auxilliary_output_2_loss: 1.2399 - final_prediction_loss: 1.3579 - auxilliary_output_1_acc: 0.6233 - auxilliary_output_2_acc: 0.5520 - final_prediction_acc: 0.5054 - val_loss: 3.1236 - val_auxilliary_output_1_loss: 0.8821 - val_auxilliary_output_2_loss: 1.0626 - val_final_prediction_loss: 1.1790 - val_auxilliary_output_1_acc: 0.6934 - val_auxilliary_output_2_acc: 0.6176 - val_final_prediction_acc: 0.5796\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.01.\n",
            " - 26s - loss: 3.2187 - auxilliary_output_1_loss: 0.9363 - auxilliary_output_2_loss: 1.1015 - final_prediction_loss: 1.1809 - auxilliary_output_1_acc: 0.6720 - auxilliary_output_2_acc: 0.6059 - final_prediction_acc: 0.5753 - val_loss: 2.8031 - val_auxilliary_output_1_loss: 0.7691 - val_auxilliary_output_2_loss: 0.9510 - val_final_prediction_loss: 1.0830 - val_auxilliary_output_1_acc: 0.7374 - val_auxilliary_output_2_acc: 0.6662 - val_final_prediction_acc: 0.6128\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.01.\n",
            " - 26s - loss: 2.8954 - auxilliary_output_1_loss: 0.8292 - auxilliary_output_2_loss: 0.9989 - final_prediction_loss: 1.0673 - auxilliary_output_1_acc: 0.7104 - auxilliary_output_2_acc: 0.6431 - final_prediction_acc: 0.6197 - val_loss: 2.4743 - val_auxilliary_output_1_loss: 0.6724 - val_auxilliary_output_2_loss: 0.8650 - val_final_prediction_loss: 0.9369 - val_auxilliary_output_1_acc: 0.7820 - val_auxilliary_output_2_acc: 0.6956 - val_final_prediction_acc: 0.6760\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.01.\n",
            " - 26s - loss: 2.6132 - auxilliary_output_1_loss: 0.7366 - auxilliary_output_2_loss: 0.9140 - final_prediction_loss: 0.9626 - auxilliary_output_1_acc: 0.7427 - auxilliary_output_2_acc: 0.6779 - final_prediction_acc: 0.6598 - val_loss: 2.1024 - val_auxilliary_output_1_loss: 0.5524 - val_auxilliary_output_2_loss: 0.7353 - val_final_prediction_loss: 0.8147 - val_auxilliary_output_1_acc: 0.8186 - val_auxilliary_output_2_acc: 0.7506 - val_final_prediction_acc: 0.7140\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 2.3401 - auxilliary_output_1_loss: 0.6409 - auxilliary_output_2_loss: 0.8299 - final_prediction_loss: 0.8693 - auxilliary_output_1_acc: 0.7777 - auxilliary_output_2_acc: 0.7074 - final_prediction_acc: 0.6938 - val_loss: 1.8921 - val_auxilliary_output_1_loss: 0.4764 - val_auxilliary_output_2_loss: 0.6756 - val_final_prediction_loss: 0.7401 - val_auxilliary_output_1_acc: 0.8450 - val_auxilliary_output_2_acc: 0.7634 - val_final_prediction_acc: 0.7460\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 2.1010 - auxilliary_output_1_loss: 0.5544 - auxilliary_output_2_loss: 0.7612 - final_prediction_loss: 0.7854 - auxilliary_output_1_acc: 0.8084 - auxilliary_output_2_acc: 0.7310 - final_prediction_acc: 0.7257 - val_loss: 1.6650 - val_auxilliary_output_1_loss: 0.3922 - val_auxilliary_output_2_loss: 0.6169 - val_final_prediction_loss: 0.6558 - val_auxilliary_output_1_acc: 0.8728 - val_auxilliary_output_2_acc: 0.7836 - val_final_prediction_acc: 0.7672\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 1.9012 - auxilliary_output_1_loss: 0.4800 - auxilliary_output_2_loss: 0.7003 - final_prediction_loss: 0.7208 - auxilliary_output_1_acc: 0.8327 - auxilliary_output_2_acc: 0.7545 - final_prediction_acc: 0.7490 - val_loss: 1.4986 - val_auxilliary_output_1_loss: 0.3324 - val_auxilliary_output_2_loss: 0.5514 - val_final_prediction_loss: 0.6148 - val_auxilliary_output_1_acc: 0.8996 - val_auxilliary_output_2_acc: 0.8124 - val_final_prediction_acc: 0.7812\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 1.6915 - auxilliary_output_1_loss: 0.4033 - auxilliary_output_2_loss: 0.6377 - final_prediction_loss: 0.6504 - auxilliary_output_1_acc: 0.8594 - auxilliary_output_2_acc: 0.7755 - final_prediction_acc: 0.7741 - val_loss: 1.3219 - val_auxilliary_output_1_loss: 0.2623 - val_auxilliary_output_2_loss: 0.4986 - val_final_prediction_loss: 0.5610 - val_auxilliary_output_1_acc: 0.9204 - val_auxilliary_output_2_acc: 0.8340 - val_final_prediction_acc: 0.8104\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 1.4454 - auxilliary_output_1_loss: 0.3218 - auxilliary_output_2_loss: 0.5662 - final_prediction_loss: 0.5574 - auxilliary_output_1_acc: 0.8883 - auxilliary_output_2_acc: 0.8011 - final_prediction_acc: 0.8069 - val_loss: 1.2355 - val_auxilliary_output_1_loss: 0.2129 - val_auxilliary_output_2_loss: 0.4831 - val_final_prediction_loss: 0.5395 - val_auxilliary_output_1_acc: 0.9370 - val_auxilliary_output_2_acc: 0.8410 - val_final_prediction_acc: 0.8130\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 1.2832 - auxilliary_output_1_loss: 0.2711 - auxilliary_output_2_loss: 0.5134 - final_prediction_loss: 0.4986 - auxilliary_output_1_acc: 0.9055 - auxilliary_output_2_acc: 0.8194 - final_prediction_acc: 0.8263 - val_loss: 0.9236 - val_auxilliary_output_1_loss: 0.1591 - val_auxilliary_output_2_loss: 0.3694 - val_final_prediction_loss: 0.3952 - val_auxilliary_output_1_acc: 0.9570 - val_auxilliary_output_2_acc: 0.8808 - val_final_prediction_acc: 0.8676\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 1.1141 - auxilliary_output_1_loss: 0.2228 - auxilliary_output_2_loss: 0.4575 - final_prediction_loss: 0.4337 - auxilliary_output_1_acc: 0.9227 - auxilliary_output_2_acc: 0.8394 - final_prediction_acc: 0.8504 - val_loss: 0.8191 - val_auxilliary_output_1_loss: 0.1218 - val_auxilliary_output_2_loss: 0.3163 - val_final_prediction_loss: 0.3811 - val_auxilliary_output_1_acc: 0.9666 - val_auxilliary_output_2_acc: 0.8992 - val_final_prediction_acc: 0.8676\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0096.\n",
            " - 26s - loss: 0.9735 - auxilliary_output_1_loss: 0.1846 - auxilliary_output_2_loss: 0.4084 - final_prediction_loss: 0.3805 - auxilliary_output_1_acc: 0.9359 - auxilliary_output_2_acc: 0.8574 - final_prediction_acc: 0.8687 - val_loss: 0.7640 - val_auxilliary_output_1_loss: 0.0875 - val_auxilliary_output_2_loss: 0.2931 - val_final_prediction_loss: 0.3834 - val_auxilliary_output_1_acc: 0.9794 - val_auxilliary_output_2_acc: 0.9022 - val_final_prediction_acc: 0.8640\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.8165 - auxilliary_output_1_loss: 0.1557 - auxilliary_output_2_loss: 0.3439 - final_prediction_loss: 0.3169 - auxilliary_output_1_acc: 0.9463 - auxilliary_output_2_acc: 0.8792 - final_prediction_acc: 0.8906 - val_loss: 0.5316 - val_auxilliary_output_1_loss: 0.0662 - val_auxilliary_output_2_loss: 0.2135 - val_final_prediction_loss: 0.2520 - val_auxilliary_output_1_acc: 0.9820 - val_auxilliary_output_2_acc: 0.9306 - val_final_prediction_acc: 0.9156\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.6818 - auxilliary_output_1_loss: 0.1248 - auxilliary_output_2_loss: 0.2992 - final_prediction_loss: 0.2579 - auxilliary_output_1_acc: 0.9574 - auxilliary_output_2_acc: 0.8936 - final_prediction_acc: 0.9116 - val_loss: 0.3751 - val_auxilliary_output_1_loss: 0.0468 - val_auxilliary_output_2_loss: 0.1618 - val_final_prediction_loss: 0.1666 - val_auxilliary_output_1_acc: 0.9870 - val_auxilliary_output_2_acc: 0.9528 - val_final_prediction_acc: 0.9450\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.5792 - auxilliary_output_1_loss: 0.1068 - auxilliary_output_2_loss: 0.2540 - final_prediction_loss: 0.2183 - auxilliary_output_1_acc: 0.9628 - auxilliary_output_2_acc: 0.9108 - final_prediction_acc: 0.9249 - val_loss: 0.3111 - val_auxilliary_output_1_loss: 0.0322 - val_auxilliary_output_2_loss: 0.1411 - val_final_prediction_loss: 0.1378 - val_auxilliary_output_1_acc: 0.9934 - val_auxilliary_output_2_acc: 0.9566 - val_final_prediction_acc: 0.9572\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.5279 - auxilliary_output_1_loss: 0.1030 - auxilliary_output_2_loss: 0.2278 - final_prediction_loss: 0.1971 - auxilliary_output_1_acc: 0.9644 - auxilliary_output_2_acc: 0.9204 - final_prediction_acc: 0.9328 - val_loss: 0.3234 - val_auxilliary_output_1_loss: 0.0267 - val_auxilliary_output_2_loss: 0.1307 - val_final_prediction_loss: 0.1660 - val_auxilliary_output_1_acc: 0.9954 - val_auxilliary_output_2_acc: 0.9574 - val_final_prediction_acc: 0.9458\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.4198 - auxilliary_output_1_loss: 0.0827 - auxilliary_output_2_loss: 0.1869 - final_prediction_loss: 0.1501 - auxilliary_output_1_acc: 0.9718 - auxilliary_output_2_acc: 0.9351 - final_prediction_acc: 0.9490 - val_loss: 0.2099 - val_auxilliary_output_1_loss: 0.0216 - val_auxilliary_output_2_loss: 0.0859 - val_final_prediction_loss: 0.1024 - val_auxilliary_output_1_acc: 0.9960 - val_auxilliary_output_2_acc: 0.9748 - val_final_prediction_acc: 0.9654\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.3707 - auxilliary_output_1_loss: 0.0737 - auxilliary_output_2_loss: 0.1662 - final_prediction_loss: 0.1308 - auxilliary_output_1_acc: 0.9751 - auxilliary_output_2_acc: 0.9413 - final_prediction_acc: 0.9553 - val_loss: 0.2149 - val_auxilliary_output_1_loss: 0.0150 - val_auxilliary_output_2_loss: 0.0915 - val_final_prediction_loss: 0.1085 - val_auxilliary_output_1_acc: 0.9972 - val_auxilliary_output_2_acc: 0.9712 - val_final_prediction_acc: 0.9606\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.3324 - auxilliary_output_1_loss: 0.0731 - auxilliary_output_2_loss: 0.1453 - final_prediction_loss: 0.1140 - auxilliary_output_1_acc: 0.9755 - auxilliary_output_2_acc: 0.9485 - final_prediction_acc: 0.9607 - val_loss: 0.1656 - val_auxilliary_output_1_loss: 0.0206 - val_auxilliary_output_2_loss: 0.0683 - val_final_prediction_loss: 0.0768 - val_auxilliary_output_1_acc: 0.9954 - val_auxilliary_output_2_acc: 0.9792 - val_final_prediction_acc: 0.9730\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.009216.\n",
            " - 26s - loss: 0.2956 - auxilliary_output_1_loss: 0.0693 - auxilliary_output_2_loss: 0.1288 - final_prediction_loss: 0.0975 - auxilliary_output_1_acc: 0.9767 - auxilliary_output_2_acc: 0.9553 - final_prediction_acc: 0.9663 - val_loss: 0.1578 - val_auxilliary_output_1_loss: 0.0154 - val_auxilliary_output_2_loss: 0.0506 - val_final_prediction_loss: 0.0919 - val_auxilliary_output_1_acc: 0.9968 - val_auxilliary_output_2_acc: 0.9856 - val_final_prediction_acc: 0.9686\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.2398 - auxilliary_output_1_loss: 0.0572 - auxilliary_output_2_loss: 0.1049 - final_prediction_loss: 0.0777 - auxilliary_output_1_acc: 0.9803 - auxilliary_output_2_acc: 0.9633 - final_prediction_acc: 0.9739 - val_loss: 0.0992 - val_auxilliary_output_1_loss: 0.0143 - val_auxilliary_output_2_loss: 0.0385 - val_final_prediction_loss: 0.0464 - val_auxilliary_output_1_acc: 0.9964 - val_auxilliary_output_2_acc: 0.9898 - val_final_prediction_acc: 0.9832\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.1863 - auxilliary_output_1_loss: 0.0519 - auxilliary_output_2_loss: 0.0819 - final_prediction_loss: 0.0525 - auxilliary_output_1_acc: 0.9829 - auxilliary_output_2_acc: 0.9728 - final_prediction_acc: 0.9831 - val_loss: 0.0975 - val_auxilliary_output_1_loss: 0.0141 - val_auxilliary_output_2_loss: 0.0392 - val_final_prediction_loss: 0.0441 - val_auxilliary_output_1_acc: 0.9980 - val_auxilliary_output_2_acc: 0.9868 - val_final_prediction_acc: 0.9858\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.1909 - auxilliary_output_1_loss: 0.0481 - auxilliary_output_2_loss: 0.0846 - final_prediction_loss: 0.0582 - auxilliary_output_1_acc: 0.9839 - auxilliary_output_2_acc: 0.9708 - final_prediction_acc: 0.9798 - val_loss: 0.1389 - val_auxilliary_output_1_loss: 0.0152 - val_auxilliary_output_2_loss: 0.0533 - val_final_prediction_loss: 0.0705 - val_auxilliary_output_1_acc: 0.9968 - val_auxilliary_output_2_acc: 0.9820 - val_final_prediction_acc: 0.9770\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.1964 - auxilliary_output_1_loss: 0.0436 - auxilliary_output_2_loss: 0.0863 - final_prediction_loss: 0.0665 - auxilliary_output_1_acc: 0.9853 - auxilliary_output_2_acc: 0.9706 - final_prediction_acc: 0.9779 - val_loss: 0.1069 - val_auxilliary_output_1_loss: 0.0075 - val_auxilliary_output_2_loss: 0.0383 - val_final_prediction_loss: 0.0612 - val_auxilliary_output_1_acc: 0.9986 - val_auxilliary_output_2_acc: 0.9880 - val_final_prediction_acc: 0.9792\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.1646 - auxilliary_output_1_loss: 0.0393 - auxilliary_output_2_loss: 0.0722 - final_prediction_loss: 0.0531 - auxilliary_output_1_acc: 0.9864 - auxilliary_output_2_acc: 0.9751 - final_prediction_acc: 0.9818 - val_loss: 0.0690 - val_auxilliary_output_1_loss: 0.0069 - val_auxilliary_output_2_loss: 0.0255 - val_final_prediction_loss: 0.0366 - val_auxilliary_output_1_acc: 0.9988 - val_auxilliary_output_2_acc: 0.9932 - val_final_prediction_acc: 0.9880\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.1514 - auxilliary_output_1_loss: 0.0360 - auxilliary_output_2_loss: 0.0672 - final_prediction_loss: 0.0481 - auxilliary_output_1_acc: 0.9881 - auxilliary_output_2_acc: 0.9772 - final_prediction_acc: 0.9838 - val_loss: 0.0603 - val_auxilliary_output_1_loss: 0.0061 - val_auxilliary_output_2_loss: 0.0225 - val_final_prediction_loss: 0.0318 - val_auxilliary_output_1_acc: 0.9986 - val_auxilliary_output_2_acc: 0.9930 - val_final_prediction_acc: 0.9904\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.1331 - auxilliary_output_1_loss: 0.0327 - auxilliary_output_2_loss: 0.0601 - final_prediction_loss: 0.0404 - auxilliary_output_1_acc: 0.9890 - auxilliary_output_2_acc: 0.9796 - final_prediction_acc: 0.9869 - val_loss: 0.0592 - val_auxilliary_output_1_loss: 0.0043 - val_auxilliary_output_2_loss: 0.0180 - val_final_prediction_loss: 0.0370 - val_auxilliary_output_1_acc: 0.9992 - val_auxilliary_output_2_acc: 0.9938 - val_final_prediction_acc: 0.9876\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            " - 26s - loss: 0.1053 - auxilliary_output_1_loss: 0.0346 - auxilliary_output_2_loss: 0.0432 - final_prediction_loss: 0.0276 - auxilliary_output_1_acc: 0.9884 - auxilliary_output_2_acc: 0.9858 - final_prediction_acc: 0.9908 - val_loss: 0.0485 - val_auxilliary_output_1_loss: 0.0074 - val_auxilliary_output_2_loss: 0.0145 - val_final_prediction_loss: 0.0266 - val_auxilliary_output_1_acc: 0.9978 - val_auxilliary_output_2_acc: 0.9952 - val_final_prediction_acc: 0.9916\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.1249 - auxilliary_output_1_loss: 0.0325 - auxilliary_output_2_loss: 0.0548 - final_prediction_loss: 0.0376 - auxilliary_output_1_acc: 0.9893 - auxilliary_output_2_acc: 0.9821 - final_prediction_acc: 0.9878 - val_loss: 0.0296 - val_auxilliary_output_1_loss: 0.0043 - val_auxilliary_output_2_loss: 0.0107 - val_final_prediction_loss: 0.0145 - val_auxilliary_output_1_acc: 0.9992 - val_auxilliary_output_2_acc: 0.9972 - val_final_prediction_acc: 0.9960\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.0858 - auxilliary_output_1_loss: 0.0251 - auxilliary_output_2_loss: 0.0380 - final_prediction_loss: 0.0227 - auxilliary_output_1_acc: 0.9920 - auxilliary_output_2_acc: 0.9868 - final_prediction_acc: 0.9922 - val_loss: 0.0198 - val_auxilliary_output_1_loss: 0.0030 - val_auxilliary_output_2_loss: 0.0074 - val_final_prediction_loss: 0.0094 - val_auxilliary_output_1_acc: 0.9996 - val_auxilliary_output_2_acc: 0.9978 - val_final_prediction_acc: 0.9962\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.0632 - auxilliary_output_1_loss: 0.0233 - auxilliary_output_2_loss: 0.0261 - final_prediction_loss: 0.0139 - auxilliary_output_1_acc: 0.9924 - auxilliary_output_2_acc: 0.9914 - final_prediction_acc: 0.9957 - val_loss: 0.0122 - val_auxilliary_output_1_loss: 0.0019 - val_auxilliary_output_2_loss: 0.0051 - val_final_prediction_loss: 0.0053 - val_auxilliary_output_1_acc: 0.9996 - val_auxilliary_output_2_acc: 0.9986 - val_final_prediction_acc: 0.9982\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.0717 - auxilliary_output_1_loss: 0.0228 - auxilliary_output_2_loss: 0.0322 - final_prediction_loss: 0.0167 - auxilliary_output_1_acc: 0.9920 - auxilliary_output_2_acc: 0.9894 - final_prediction_acc: 0.9946 - val_loss: 0.0257 - val_auxilliary_output_1_loss: 0.0037 - val_auxilliary_output_2_loss: 0.0081 - val_final_prediction_loss: 0.0139 - val_auxilliary_output_1_acc: 0.9994 - val_auxilliary_output_2_acc: 0.9970 - val_final_prediction_acc: 0.9956\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.0793 - auxilliary_output_1_loss: 0.0244 - auxilliary_output_2_loss: 0.0344 - final_prediction_loss: 0.0205 - auxilliary_output_1_acc: 0.9918 - auxilliary_output_2_acc: 0.9883 - final_prediction_acc: 0.9931 - val_loss: 0.0304 - val_auxilliary_output_1_loss: 0.0041 - val_auxilliary_output_2_loss: 0.0086 - val_final_prediction_loss: 0.0177 - val_auxilliary_output_1_acc: 0.9996 - val_auxilliary_output_2_acc: 0.9976 - val_final_prediction_acc: 0.9926\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.0655 - auxilliary_output_1_loss: 0.0185 - auxilliary_output_2_loss: 0.0306 - final_prediction_loss: 0.0163 - auxilliary_output_1_acc: 0.9941 - auxilliary_output_2_acc: 0.9900 - final_prediction_acc: 0.9946 - val_loss: 0.0122 - val_auxilliary_output_1_loss: 0.0013 - val_auxilliary_output_2_loss: 0.0045 - val_final_prediction_loss: 0.0064 - val_auxilliary_output_1_acc: 0.9998 - val_auxilliary_output_2_acc: 0.9990 - val_final_prediction_acc: 0.9980\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.0645 - auxilliary_output_1_loss: 0.0183 - auxilliary_output_2_loss: 0.0294 - final_prediction_loss: 0.0168 - auxilliary_output_1_acc: 0.9942 - auxilliary_output_2_acc: 0.9905 - final_prediction_acc: 0.9946 - val_loss: 0.0252 - val_auxilliary_output_1_loss: 0.0016 - val_auxilliary_output_2_loss: 0.0080 - val_final_prediction_loss: 0.0156 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9976 - val_final_prediction_acc: 0.9952\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            " - 26s - loss: 0.0812 - auxilliary_output_1_loss: 0.0171 - auxilliary_output_2_loss: 0.0374 - final_prediction_loss: 0.0267 - auxilliary_output_1_acc: 0.9948 - auxilliary_output_2_acc: 0.9879 - final_prediction_acc: 0.9912 - val_loss: 0.0131 - val_auxilliary_output_1_loss: 0.0011 - val_auxilliary_output_2_loss: 0.0031 - val_final_prediction_loss: 0.0088 - val_auxilliary_output_1_acc: 0.9998 - val_auxilliary_output_2_acc: 0.9994 - val_final_prediction_acc: 0.9970\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0462 - auxilliary_output_1_loss: 0.0149 - auxilliary_output_2_loss: 0.0207 - final_prediction_loss: 0.0106 - auxilliary_output_1_acc: 0.9951 - auxilliary_output_2_acc: 0.9935 - final_prediction_acc: 0.9965 - val_loss: 0.0272 - val_auxilliary_output_1_loss: 0.0011 - val_auxilliary_output_2_loss: 0.0087 - val_final_prediction_loss: 0.0174 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9974 - val_final_prediction_acc: 0.9948\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0607 - auxilliary_output_1_loss: 0.0179 - auxilliary_output_2_loss: 0.0258 - final_prediction_loss: 0.0171 - auxilliary_output_1_acc: 0.9943 - auxilliary_output_2_acc: 0.9914 - final_prediction_acc: 0.9944 - val_loss: 0.0133 - val_auxilliary_output_1_loss: 0.0010 - val_auxilliary_output_2_loss: 0.0053 - val_final_prediction_loss: 0.0070 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9984 - val_final_prediction_acc: 0.9976\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0488 - auxilliary_output_1_loss: 0.0160 - auxilliary_output_2_loss: 0.0204 - final_prediction_loss: 0.0124 - auxilliary_output_1_acc: 0.9945 - auxilliary_output_2_acc: 0.9937 - final_prediction_acc: 0.9960 - val_loss: 0.0237 - val_auxilliary_output_1_loss: 9.4168e-04 - val_auxilliary_output_2_loss: 0.0081 - val_final_prediction_loss: 0.0147 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9978 - val_final_prediction_acc: 0.9938\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0458 - auxilliary_output_1_loss: 0.0134 - auxilliary_output_2_loss: 0.0199 - final_prediction_loss: 0.0125 - auxilliary_output_1_acc: 0.9957 - auxilliary_output_2_acc: 0.9932 - final_prediction_acc: 0.9962 - val_loss: 0.0116 - val_auxilliary_output_1_loss: 6.6487e-04 - val_auxilliary_output_2_loss: 0.0044 - val_final_prediction_loss: 0.0066 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9988 - val_final_prediction_acc: 0.9972\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0422 - auxilliary_output_1_loss: 0.0149 - auxilliary_output_2_loss: 0.0178 - final_prediction_loss: 0.0094 - auxilliary_output_1_acc: 0.9952 - auxilliary_output_2_acc: 0.9946 - final_prediction_acc: 0.9969 - val_loss: 0.0097 - val_auxilliary_output_1_loss: 9.6294e-04 - val_auxilliary_output_2_loss: 0.0035 - val_final_prediction_loss: 0.0053 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9986 - val_final_prediction_acc: 0.9980\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0493 - auxilliary_output_1_loss: 0.0123 - auxilliary_output_2_loss: 0.0232 - final_prediction_loss: 0.0138 - auxilliary_output_1_acc: 0.9960 - auxilliary_output_2_acc: 0.9924 - final_prediction_acc: 0.9955 - val_loss: 0.0382 - val_auxilliary_output_1_loss: 0.0010 - val_auxilliary_output_2_loss: 0.0107 - val_final_prediction_loss: 0.0264 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9968 - val_final_prediction_acc: 0.9924\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0500 - auxilliary_output_1_loss: 0.0146 - auxilliary_output_2_loss: 0.0217 - final_prediction_loss: 0.0138 - auxilliary_output_1_acc: 0.9951 - auxilliary_output_2_acc: 0.9932 - final_prediction_acc: 0.9955 - val_loss: 0.0084 - val_auxilliary_output_1_loss: 6.7701e-04 - val_auxilliary_output_2_loss: 0.0037 - val_final_prediction_loss: 0.0041 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9988 - val_final_prediction_acc: 0.9988\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            " - 26s - loss: 0.0455 - auxilliary_output_1_loss: 0.0149 - auxilliary_output_2_loss: 0.0209 - final_prediction_loss: 0.0098 - auxilliary_output_1_acc: 0.9949 - auxilliary_output_2_acc: 0.9934 - final_prediction_acc: 0.9968 - val_loss: 0.0049 - val_auxilliary_output_1_loss: 8.2264e-04 - val_auxilliary_output_2_loss: 0.0017 - val_final_prediction_loss: 0.0024 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9996 - val_final_prediction_acc: 0.9994\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            " - 26s - loss: 0.0312 - auxilliary_output_1_loss: 0.0117 - auxilliary_output_2_loss: 0.0133 - final_prediction_loss: 0.0063 - auxilliary_output_1_acc: 0.9964 - auxilliary_output_2_acc: 0.9958 - final_prediction_acc: 0.9979 - val_loss: 0.0074 - val_auxilliary_output_1_loss: 6.4847e-04 - val_auxilliary_output_2_loss: 0.0024 - val_final_prediction_loss: 0.0044 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9992 - val_final_prediction_acc: 0.9988\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            " - 26s - loss: 0.0246 - auxilliary_output_1_loss: 0.0100 - auxilliary_output_2_loss: 0.0100 - final_prediction_loss: 0.0047 - auxilliary_output_1_acc: 0.9967 - auxilliary_output_2_acc: 0.9968 - final_prediction_acc: 0.9986 - val_loss: 0.0069 - val_auxilliary_output_1_loss: 4.6370e-04 - val_auxilliary_output_2_loss: 0.0019 - val_final_prediction_loss: 0.0045 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9994 - val_final_prediction_acc: 0.9982\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            " - 26s - loss: 0.0232 - auxilliary_output_1_loss: 0.0101 - auxilliary_output_2_loss: 0.0097 - final_prediction_loss: 0.0034 - auxilliary_output_1_acc: 0.9966 - auxilliary_output_2_acc: 0.9969 - final_prediction_acc: 0.9991 - val_loss: 0.0060 - val_auxilliary_output_1_loss: 4.1449e-04 - val_auxilliary_output_2_loss: 0.0023 - val_final_prediction_loss: 0.0033 - val_auxilliary_output_1_acc: 1.0000 - val_auxilliary_output_2_acc: 0.9996 - val_final_prediction_acc: 0.9988\n",
            "Time taken to train the model: 1328.3071949629993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKgNkQQBebnv",
        "colab_type": "code",
        "outputId": "2b96dca5-ea78-4fbe-a812-a8f14d4700b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = inceptionV2Model.evaluate(xtest, [ytest,ytest,ytest], verbose=0, batch_size=10)\n",
        "print('loss','accuracy:')\n",
        "print(score)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss accuracy:\n",
            "[2.302591649532318, 0.1000000018775463]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}